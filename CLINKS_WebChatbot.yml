app:
  description: „ÉÅ„Éº„É†ÁõÆÊ®ô 1~3Êúà
  icon: üìë
  icon_background: '#EFF1F5'
  mode: advanced-chat
  name: 'CLINKS_WebChatbot '
  use_icon_as_answer_icon: true
kind: app
version: 0.1.5
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        sourceType: llm
        targetType: answer
      id: 1711528917469-1711528919501
      source: '1711528917469'
      sourceHandle: source
      target: '1711528919501'
      targetHandle: target
      type: custom
    - data:
        isInIteration: false
        sourceType: start
        targetType: if-else
      id: 1711528914102-source-1738584377542-target
      source: '1711528914102'
      sourceHandle: source
      target: '1738584377542'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: knowledge-retrieval
      id: 1738584377542-true-17385846312060-target
      source: '1738584377542'
      sourceHandle: 'true'
      target: '17385846312060'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: 17385846312060-source-1711528917469-target
      source: '17385846312060'
      sourceHandle: source
      target: '1711528917469'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17385847659560-source-17385847792280-target
      source: '17385847659560'
      sourceHandle: source
      target: '17385847792280'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: 1738584377542-false-17385847659560-target
      selected: false
      source: '1738584377542'
      sourceHandle: 'false'
      target: '17385847659560'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: knowledge-retrieval
      id: 1738584377542-7e9055b2-25a8-4e7b-af0a-cc79480078e5-17397928769690-target
      source: '1738584377542'
      sourceHandle: 7e9055b2-25a8-4e7b-af0a-cc79480078e5
      target: '17397928769690'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: 17397928769690-source-17397927370860-target
      source: '17397928769690'
      sourceHandle: source
      target: '17397927370860'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17397927370860-source-17397929685710-target
      source: '17397927370860'
      sourceHandle: source
      target: '17397929685710'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: Start
        type: start
        variables: []
      height: 54
      id: '1711528914102'
      position:
        x: 79.5
        y: 2634.5
      positionAbsolute:
        x: 79.5
        y: 2634.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - sys
          - query
        desc: Invoking large language models to answer questions or process natural
          language
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params:
            frequency_penalty: 0
            max_tokens: 512
            presence_penalty: 0
            temperature: 0.7
            top_p: 1
          mode: chat
          name: gemini-2.0-flash-exp
          provider: google
        prompt_template:
        - id: 9b6f207d-9ca1-4cd7-a936-9ac543e96ded
          role: system
          text: "You are a helpful assistant. \nUse the following context as your\
            \ learned knowledge, inside <context></context> XML tags.\n<context>\n\
            {{#context#}}\n</context>\nWhen answer to user:\n- If you don't know,\
            \ just say that you don't know.\n- If you don't know when you are not\
            \ sure, ask for clarification.\nAvoid mentioning that you obtained the\
            \ information from the context.\nAnd answer according to the language\
            \ of the user's question."
        selected: false
        title: LLM2
        type: llm
        variables: []
        vision:
          enabled: false
      height: 158
      id: '1711528917469'
      position:
        x: 943.9138524555651
        y: 2549.681655674259
      positionAbsolute:
        x: 943.9138524555651
        y: 2549.681655674259
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1711528917469.text#}}'
        desc: ''
        selected: false
        title: Answer
        type: answer
        variables: []
      height: 103
      id: '1711528919501'
      position:
        x: 1212.5693610728024
        y: 2549.681655674259
      positionAbsolute:
        x: 1212.5693610728024
        y: 2549.681655674259
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: contains
            id: e170c671-fa5e-42ea-affc-acb4afd3670c
            value: RES
            varType: string
            variable_selector:
            - sys
            - query
          id: 'true'
          logical_operator: or
        - case_id: 7e9055b2-25a8-4e7b-af0a-cc79480078e5
          conditions:
          - comparison_operator: contains
            id: c8065969-4230-4951-ada3-6dd28518ef6e
            value: „ÉÜ„É¨„ÉØ„Éº„ÇØ
            varType: string
            variable_selector:
            - sys
            - query
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE
        type: if-else
      height: 174
      id: '1738584377542'
      position:
        x: 379.1647126045142
        y: 2611.5573913190124
      positionAbsolute:
        x: 379.1647126045142
        y: 2611.5573913190124
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        dataset_ids:
        - b21de71f-31fd-4ef1-936e-0770ffb1d03d
        desc: Allows you to query text content related to user questions from the
          Knowledge
        multiple_retrieval_config:
          reranking_enable: true
          reranking_mode: reranking_model
          reranking_model:
            model: rerank-english-v2.0
            provider: cohere
          score_threshold: 0.8
          top_k: 1
        query_variable_selector:
        - '1711528914102'
        - sys.query
        retrieval_mode: multiple
        selected: false
        single_retrieval_config:
          model:
            completion_params:
              frequency_penalty: 0
              max_tokens: 512
              presence_penalty: 0
              temperature: 0
              top_p: 1
            mode: chat
            name: gpt-3.5-turbo
            provider: openai
        title: Knowledge Retrieval (1)
        type: knowledge-retrieval
      height: 114
      id: '17385846312060'
      position:
        x: 673.0386359924473
        y: 2549.681655674259
      positionAbsolute:
        x: 673.0386359924473
        y: 2549.681655674259
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - sys
          - query
        desc: Invoking large language models to answer questions or process natural
          language
        memory:
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params:
            frequency_penalty: 0
            max_tokens: 512
            presence_penalty: 0
            temperature: 0.7
            top_p: 1
          mode: chat
          name: gemini-2.0-flash-exp
          provider: google
        prompt_template:
        - id: 9b6f207d-9ca1-4cd7-a936-9ac543e96ded
          role: system
          text: "```xml\n<prompt_template>\n  <instructions>\n    <step>1. ÂÖ•Âäõ„Åï„Çå„Åü„ÉÜ„Ç≠„Çπ„Éà„ÇíÊ≥®ÊÑèÊ∑±„ÅèË™≠„Åø„ÄÅ„Åù„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åó„Çà„ÅÜ„Å®Ë©¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>2. „ÉÜ„Ç≠„Çπ„Éà„ÅÆÊÑèÂë≥„ÅåÊòéÁ¢∫„Å´ÁêÜËß£„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÄÅ„Åæ„Åü„ÅØ„ÉÜ„Ç≠„Çπ„Éà„ÅåÊÑèÂë≥„Çí„Å™„Åï„Å™„ÅÑ„ÄÅ„ÅÇ„Çã„ÅÑ„ÅØÊñáÊ≥ïÁöÑ„Å´Ë™§„Å£„Å¶„ÅÑ„Çã„Å®Âà§Êñ≠„Åó„ÅüÂ†¥Âêà„ÄÅÊ¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„Å´ÈÄ≤„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>3. „ÉÜ„Ç≠„Çπ„Éà„ÅÆÊÑèÂë≥„ÅåÁêÜËß£„Åß„Åç„Å™„ÅÑ„Å®„ÅÑ„ÅÜ‰∫ãÂÆü„ÇíÊòéÁ¢∫„Å´‰ºù„Åà„ÇãÂõûÁ≠î„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂõûÁ≠î„ÅØÁ∞°ÊΩî„Åã„Å§Áõ¥Êé•ÁöÑ„Åß„ÅÇ„Çã„Åπ„Åç„Åß„Åô„ÄÇ</step>\n\
            \    <step>4. ÂõûÁ≠î„ÅØ„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®„ÅÑ„ÅÜ„Éï„É¨„Éº„Ç∫„ÅÆ„Åø„ÅßÊßãÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰ªñ„ÅÆË®ÄËëâ„ÇÑË™¨Êòé„ÄÅ„Åæ„Åü„ÅØËøΩÂä†„ÅÆÊñá„ÇíÂê´„ÇÅ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>5. ÂõûÁ≠î„Å´„ÅØ„ÄÅXML„Çø„Ç∞„ÇíÂê´„ÇÅ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇÂá∫Âäõ„ÅØ„Éó„É¨„Éº„É≥„ÉÜ„Ç≠„Çπ„Éà„Åß„ÅÇ„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ</step>\n   \
            \ <step>6. ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅåÊó•Êú¨Ë™û„Åß„ÅÇ„Çã„Åã„ÄÅ‰ªñ„ÅÆË®ÄË™û„Åß„ÅÇ„Çã„Åã„Å´Èñ¢„Çè„Çâ„Åö„ÄÅÂõûÁ≠î„ÅØÂ∏∏„Å´Êó•Êú¨Ë™û„Åß„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®Âá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>7. ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅåÁ©∫„ÅÆÂ†¥Âêà„ÄÅ„Åæ„Åü„ÅØÁ©∫ÁôΩÊñáÂ≠ó„ÅÆ„Åø„ÅßÊßãÊàê„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÇÇ„ÄÅÂêåÊßò„Å´„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>8. ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅåÈùûÂ∏∏„Å´Èï∑„Åè„ÄÅË§áÈõë„Å™ÊßãÈÄ†„Çí„Åó„Å¶„ÅÑ„ÇãÂ†¥Âêà„Åß„ÇÇ„ÄÅÊÑèÂë≥„ÅåÁêÜËß£„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄÅËø∑„Çè„Åö„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÊÑèÂë≥„ÇíÁêÜËß£„Åó„Çà„ÅÜ„Å®ÈÅéÂ∫¶„Å´ÊôÇÈñì„ÇíË≤ª„ÇÑ„ÅôÂøÖË¶Å„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ</step>\n\
            \    <step>9. ÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„Åå‰∏ÄÈÉ®„ÅÆ„ÅøÁêÜËß£„Åß„Åç„ÇãÂ†¥Âêà„Åß„ÇÇ„ÄÅÂÖ®‰Ωì„Å®„Åó„Å¶ÊÑèÂë≥„ÅåÁêÜËß£„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄÅ„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÈÉ®ÂàÜÁöÑ„Å™ÁêÜËß£„Å´Âü∫„Å•„ÅÑ„Å¶Êé®Ê∏¨„ÇÑËß£Èáà„ÇíË©¶„Åø„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \    <step>10. ÂõûÁ≠î„ÇíÁîüÊàê„Åô„ÇãÈöõ„Å´„ÅØ„ÄÅÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÅÆÂÜÖÂÆπ„ÇíË®òÊÜ∂„Åó„Åü„Çä„ÄÅÈÅéÂéª„ÅÆÂõûÁ≠î„Å®„ÅÆÈñ¢ÈÄ£ÊÄß„ÇíËÄÉÊÖÆ„Åó„Åü„Çä„Åô„ÇãÂøÖË¶Å„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÂêÑÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„Å´ÂØæ„Åó„Å¶Áã¨Á´ã„Åó„Å¶Âà§Êñ≠„Åó„ÄÅÊÑèÂë≥„ÅåÁêÜËß£„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄåÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</step>\n\
            \  </instructions>\n  <examples>\n    <example>\n      <input>„Åì„Çì„Å´„Å°„ÅØ</input>\n\
            \      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n    </example>\n    <example>\n   \
            \   <input>„Åì„Çå„ÅØ„ÉÜ„Çπ„Éà„Åß„Åô„ÄÇ</input>\n      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n    </example>\n\
            \    <example>\n      <input>asdfghjkl</input>\n      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n\
            \    </example>\n    <example>\n      <input>ÊÑèÂë≥‰∏çÊòé„Å™ÊñáÁ´†„ÅåÂÖ•Âäõ„Åï„Çå„Åæ„Åó„Åü„ÄÇ</input>\n\
            \      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n    </example>\n    <example>\n   \
            \   <input>1234567890</input>\n      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n    </example>\n\
            \    <example>\n      <input>   </input>\n      <output>ÊÑèÂë≥„Åå„Çè„Åã„Çä„Åæ„Åõ„Çì</output>\n\
            \    </example>\n  </examples>\n</prompt_template>\n```\n"
        selected: false
        title: LLM
        type: llm
        variables: []
        vision:
          enabled: false
      height: 158
      id: '17385847659560'
      position:
        x: 659.4713263520216
        y: 3053.1888580107025
      positionAbsolute:
        x: 659.4713263520216
        y: 3053.1888580107025
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#17385847659560.text#}}'
        desc: ''
        selected: false
        title: Answer (1)
        type: answer
        variables: []
      height: 103
      id: '17385847792280'
      position:
        x: 1219.3292138165464
        y: 3073.7786237225014
      positionAbsolute:
        x: 1219.3292138165464
        y: 3073.7786237225014
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: Invoking large language models to answer questions or process natural
          language
        memory:
          query_prompt_template: ''
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params:
            frequency_penalty: 0
            max_tokens: 512
            presence_penalty: 0
            temperature: 0.7
            top_p: 1
          mode: chat
          name: gemini-2.0-flash-exp
          provider: google
        prompt_template:
        - id: 9b6f207d-9ca1-4cd7-a936-9ac543e96ded
          role: system
          text: "You are a helpful assistant. \nUse the following context as your\
            \ learned knowledge, inside <context></context> XML tags.\n<context>\n\
            {{#context#}}\n</context>\nWhen answer to user:\n- If you don't know,\
            \ just say that you don't know.\n- If you don't know when you are not\
            \ sure, ask for clarification.\nAvoid mentioning that you obtained the\
            \ information from the context.\nAnd answer according to the language\
            \ of the user's question."
        selected: false
        title: LLM2
        type: llm
        variables: []
        vision:
          enabled: false
      height: 158
      id: '17397927370860'
      position:
        x: 931.3978136606684
        y: 2779.6455259220334
      positionAbsolute:
        x: 931.3978136606684
        y: 2779.6455259220334
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        dataset_ids:
        - e1594b3c-be52-4f5f-a146-09ccc7516fd8
        desc: Allows you to query text content related to user questions from the
          Knowledge
        multiple_retrieval_config:
          reranking_enable: true
          reranking_mode: reranking_model
          reranking_model:
            model: rerank-english-v2.0
            provider: cohere
          score_threshold: 0.8
          top_k: 3
        query_variable_selector:
        - '1711528914102'
        - sys.query
        retrieval_mode: multiple
        selected: false
        single_retrieval_config:
          model:
            completion_params:
              frequency_penalty: 0
              max_tokens: 512
              presence_penalty: 0
              temperature: 0
              top_p: 1
            mode: chat
            name: gpt-3.5-turbo
            provider: openai
        title: Knowledge Retrieval (2)
        type: knowledge-retrieval
      height: 114
      id: '17397928769690'
      position:
        x: 668.4217736269475
        y: 2779.6455259220334
      positionAbsolute:
        x: 668.4217736269475
        y: 2779.6455259220334
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#17397927370860.text#}}'
        desc: ''
        selected: false
        title: Answer (1)
        type: answer
        variables: []
      height: 103
      id: '17397929685710'
      position:
        x: 1212.5693610728024
        y: 2779.6455259220334
      positionAbsolute:
        x: 1212.5693610728024
        y: 2779.6455259220334
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: 28.201851385840882
      y: -1851.454081100842
      zoom: 0.764738456537664
